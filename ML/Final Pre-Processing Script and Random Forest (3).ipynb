{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed580d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library needed\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "import scipy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time\n",
    "import pickle\n",
    "import copy\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "263237b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing(dat,train_dat):\n",
    "    \n",
    "    ### SALARY PROCESSING \n",
    "    # see if character is in text\n",
    "    def alpha_in_text(text):\n",
    "        return(any(c.isalpha() for c in text))\n",
    "\n",
    "    # see how many dashes are in text\n",
    "    def number_of_dashes(text):\n",
    "        return(sum([1 for i in text if '-' in i]))\n",
    "\n",
    "    # extract smallest salary range value\n",
    "    def salary_extract_first(text):\n",
    "\n",
    "        if pd.isna(text) is True:\n",
    "            return(-1)\n",
    "\n",
    "        elif alpha_in_text(text) is True:\n",
    "            return(-2)\n",
    "\n",
    "        elif '-' in text:\n",
    "            if number_of_dashes(text) == 1:\n",
    "                if re.split('-',text)[0].isdigit() is True:\n",
    "                    return(float(re.split('-',text)[0]))\n",
    "                else:\n",
    "                    return(-1)\n",
    "\n",
    "            else:\n",
    "                return(-1)\n",
    "        else:\n",
    "            return(-1)\n",
    "\n",
    "    # largest salary range value\n",
    "    def salary_extract_second(text):\n",
    "\n",
    "        if pd.isna(text) is True:\n",
    "            return(-1)\n",
    "\n",
    "        elif alpha_in_text(text) is True:\n",
    "            return(-2)\n",
    "\n",
    "        elif '-' in text:\n",
    "            if number_of_dashes(text) == 1:\n",
    "                if re.split('-',text)[1].isdigit() is True:\n",
    "                    return(float(re.split('-',text)[1]))\n",
    "                else:\n",
    "                    return(-1)\n",
    "\n",
    "            else:\n",
    "                return(-1)\n",
    "        else:\n",
    "            return(-1)\n",
    "\n",
    "    # convert numeric salary to category\n",
    "    def salary_category_first(number):\n",
    "        percentile = [60.0, 14000.0, 20000.0, 30000.0, 35000.0, 44374.4, 55000.0, 70000.0, 90000.0]\n",
    "        if number == -1:\n",
    "            return(str(1))\n",
    "\n",
    "        if number == -2:\n",
    "            return(str(2))\n",
    "\n",
    "        for i in range(len(percentile)):\n",
    "            if i not in {0,8}:\n",
    "                if (number > percentile[i-1]) & (number <= percentile[i]):\n",
    "                    return(str(i+3))\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            if i == 0:\n",
    "                if number < percentile[0]:\n",
    "                    return(str(i+3))\n",
    "            if i == 8:\n",
    "                if number >= percentile[8]:\n",
    "                    return(str(i+3))\n",
    "\n",
    "\n",
    "\n",
    "    def salary_category_second(number):\n",
    "        percentile = [120, 20000.0, 30000.0, 40000.0, 50000.0, 65000.0, 80000.0, 100000.0, 130000.0]\n",
    "        if number == -1:\n",
    "            return(str(1))\n",
    "\n",
    "        if number == -2:\n",
    "            return(str(2))\n",
    "\n",
    "        for i in range(len(percentile)):\n",
    "            if i not in {0,8}:\n",
    "                if (number > percentile[i-1]) & (number <= percentile[i]):\n",
    "                    return(str(i+3))\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            if i == 0:\n",
    "                if number < percentile[0]:\n",
    "                    return(str(i+3))\n",
    "            if i == 8:\n",
    "                if number >= percentile[8]:\n",
    "                    return(str(i+3))\n",
    "    \n",
    "    \n",
    "    ### ONE HOT ENCODING (training)\n",
    "    employment_type_onehot = OneHotEncoder(handle_unknown='ignore').fit(train_dat[['employment_type']].fillna('NaN'))\n",
    "    required_experience_onehot = OneHotEncoder(handle_unknown='ignore').fit(train_dat[['required_experience']].fillna('NaN'))\n",
    "    required_education_onehot = OneHotEncoder(handle_unknown='ignore').fit(train_dat[['required_education']].fillna('NaN'))\n",
    "    industry_onehot = OneHotEncoder(handle_unknown='ignore').fit(train_dat[['industry']].fillna('NaN'))\n",
    "    function_onehot = OneHotEncoder(handle_unknown='ignore').fit(train_dat[['function.']].fillna('NaN'))\n",
    "    category_1 = train_dat.salary_range.apply(salary_extract_first).apply(salary_category_first)\n",
    "    category_2 = train_dat.salary_range.apply(salary_extract_second).apply(salary_category_second)\n",
    "    salary_1_onehot = OneHotEncoder(handle_unknown='ignore').fit(pd.DataFrame(category_1))\n",
    "    salary_2_onehot = OneHotEncoder(handle_unknown='ignore').fit(pd.DataFrame(category_2))\n",
    "    profile_onehot = TfidfVectorizer(token_pattern = r\"[A-Za-z]+\").fit(train_dat['company_profile'].fillna('NaN'))\n",
    "    description_onehot = TfidfVectorizer(token_pattern = r\"[A-Za-z]+\").fit(train_dat['description'].fillna('NaN'))\n",
    "    requirements_onehot = TfidfVectorizer(token_pattern = r\"[A-Za-z]+\").fit(train_dat['requirements'].fillna('NaN'))\n",
    "    benefits_onehot = TfidfVectorizer(token_pattern = r\"[A-Za-z]+\").fit(train_dat['benefits'].fillna('NaN'))\n",
    "    \n",
    "    # transforming to one hot encoding\n",
    "    profile_transformed = pd.DataFrame.sparse.from_spmatrix(profile_onehot.transform(dat['company_profile'].fillna('NaN')))\n",
    "    description_transformed = pd.DataFrame.sparse.from_spmatrix(description_onehot.transform(dat['description'].fillna('NaN')))\n",
    "    requirements_transformed = pd.DataFrame.sparse.from_spmatrix(requirements_onehot.transform(dat['required_education'].fillna('NaN')))\n",
    "    benefits_transformed = pd.DataFrame.sparse.from_spmatrix(benefits_onehot.transform(dat['benefits'].fillna('NaN')))\n",
    "    \n",
    "    names = [['profile.'+ words for words in profile_onehot.get_feature_names()],\n",
    "            ['description.'+ words for words in description_onehot.get_feature_names()],\n",
    "            ['requirements.'+ words for words in requirements_onehot.get_feature_names()],\n",
    "            ['benefits.'+ words for words in benefits_onehot.get_feature_names()]]\n",
    "    \n",
    "    descriptive = pd.concat([profile_transformed,description_transformed,requirements_transformed,benefits_transformed],axis=1,ignore_index=True)\n",
    "    descriptive.columns = [item for sublist in names for item in sublist]\n",
    "    \n",
    "    ### OTHER PARSING\n",
    "    nacols = dat.isna()[['title', 'location', 'department', 'salary_range','description', 'requirements', 'benefits',\n",
    "                      'telecommuting', 'has_company_logo', 'has_questions', 'employment_type',\n",
    "                      'required_experience', 'required_education', 'industry', 'function.']].astype('int')\n",
    "    \n",
    "    numeric_cols = dat[['telecommuting', 'has_company_logo', 'has_questions']]\n",
    "    # func to count words in document\n",
    "    document_word_count = lambda document: len(document.split(' '))\n",
    "    \n",
    "    # count words in column\n",
    "    columns = [\"company_profile\",\"description\",\"requirements\",\"benefits\"]\n",
    "    df = copy.deepcopy(dat[columns])\n",
    "    for column in columns:\n",
    "            df[(str(column) + \"_length\")] = dat[column].apply(lambda x: len(x) if x == x else 0)\n",
    "    \n",
    "    \n",
    "    # salary column one hot\n",
    "    category_1 = dat.salary_range.apply(salary_extract_first).apply(salary_category_first)\n",
    "    category_2 = dat.salary_range.apply(salary_extract_second).apply(salary_category_second)\n",
    "    \n",
    "    salary_1_transform = pd.DataFrame.sparse.from_spmatrix(salary_1_onehot.transform(pd.DataFrame(category_1)))\n",
    "    salary_2_transform = pd.DataFrame.sparse.from_spmatrix(salary_2_onehot.transform(pd.DataFrame(category_2)))\n",
    "    \n",
    "    # transform to one hot\n",
    "    employment_type_transformed =  pd.DataFrame.sparse.from_spmatrix(employment_type_onehot.transform(dat[['employment_type']].fillna('NaN')))\n",
    "    required_experience_transformed =  pd.DataFrame.sparse.from_spmatrix(required_experience_onehot.transform(dat[['required_experience']].fillna('NaN')))\n",
    "    required_education_transformed =  pd.DataFrame.sparse.from_spmatrix(required_education_onehot.transform(dat[['required_education']].fillna('NaN')))\n",
    "    industry_transformed =  pd.DataFrame.sparse.from_spmatrix(industry_onehot.transform(dat[['industry']].fillna('NaN')))\n",
    "    function_transformed =  pd.DataFrame.sparse.from_spmatrix(function_onehot.transform(dat[['function.']].fillna('NaN')))\n",
    "    \n",
    "    \n",
    "    return(pd.concat([nacols,salary_1_transform, salary_2_transform,df.iloc[:,4:],\n",
    "                      employment_type_transformed, required_experience_transformed, required_education_transformed, industry_transformed,function_transformed,numeric_cols,\n",
    "                     descriptive],axis = 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a7ce54",
   "metadata": {},
   "source": [
    "# 1. import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67ce13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Final Random Forest Model.pkl', 'rb') as inp:\n",
    "    pipe = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df190124",
   "metadata": {},
   "source": [
    "# 2. import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6465bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_train = pd.read_csv(\"job_training_data.csv\")\n",
    "dat_test = pd.read_csv(\"job_verification_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5595ab0f",
   "metadata": {},
   "source": [
    "# 3. parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78618d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = parsing(dat_test,dat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52c05eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_test\n",
    "y_test = dat_test.fraudulent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f38f86",
   "metadata": {},
   "source": [
    "# 4. classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc92514b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sean\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:515: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[932,  18],\n",
       "       [ 10,  40]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(y_test,pipe.predict_proba(X_test)[:,1]>0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16e0f2e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sean\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:515: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.972"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,pipe.predict_proba(X_test)[:,1]>0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28d42e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sean\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:515: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,pipe.predict_proba(X_test)[:,1]>0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
